# -*- coding: utf-8 -*-
"""Machine_Learning_with_Python Programming Language.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-5JkNqvES17Pz4wWhAFP_1zS6dqXKC1u

PyDrive dan Google Drive
---
Penggunaan Google drive dan menghubungkan pada Google drive menggunakan authentikasi Credential menggunakan perinta berikut :

```
!pip install -U -q PyDrive
```
"""

!pip install -U -q PyDrive

"""Using simpel authentication for initialize Google drive with Google Credential
---

"""

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

"""add to miniconda repo for packages use miniconda on google colabolatory
---
digunakan untuk mengakses local account dan local akun pada google drive masing masing akun gmail pengguna
```
!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
!chmod +x Miniconda3-latest-Linux-x86_64.sh
!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local
```



"""

!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
!chmod +x Miniconda3-latest-Linux-x86_64.sh
!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local

"""add to path miniiconda3"""

import sys
sys.path.append('/usr/local/lib/python3.7/site-packages/')

!conda --version

!conda install -y numpy

"""Numpy
---
Numpy adalah sebuah variabel kemampuan untuk mengolah data dalam List dan tuple dibidang analisis datadalam python, Kekurangan Numpy ini adalah mendorong untuk dibuatnya library tambahan yaitu Numpy(Numerical Number of Python)

"""

#Masukan data Numpy dalam listing Python
import numpy as np
x = np.array ([1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 22, 23, 24, 25])

#cetak nilai x
print(x)

#mengambil elemen dari array
x [4:8]

#mengubah elemen dan mengganti ke elemen 9
x[8] = 0
print(x)

#numPy dapat membuat array multidimens yang bertujuan sebagai melakukan komputasi dengan matriks
y = np.array([1, 3, 5, 6, 7, 8, 9, 17, 13, 11, 56, 47, 87])
print(y)

"""Pyplot
---
memvisualisasikan data dalam bentuk grafis dengan menggunakan Library tambahan yaitu Matplotlib sebagai membuat grafik dua dimensi dengan data data yang sudah di manipulasi dan dapat menampilkan data menggunakan Pyplot(untuk menampilkan histogram, diagram batang, line chart dan macam macam lagi)

hanya perlu menambhakan beberapa perintah saja untuk menampilkan diagram PyPlot di representasikan menggunakan PyPlot()
"""

import numpy as np
import matplotlib.pyplot as plt

#showing DataPlot
data = np.array( [1, 3, 5, 7, 9, 11, 13, 15, 16, 18, 20])
plt.plot(data)

"""pada data analisis atau Data Science ini hal yangs ering dilakukan untuk menganlisis sebuah histogram adalah ScatterPlot(diagram tebar) yang berguna untuk menampilkan hungan dua variabel yang berstatus(hubungan positive dan negative)"""

##scatter plot menyediakan method scatter(x, y) untuk kepentingan argumen dengan numpy
import numpy as np
import matplotlib.pyplot as plt
usia = np.array([1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 29])
tinggi = np.array([80, 70, 90, 85, 110, 120, 100, 125, 130, 160, 165, 170, 170, 168])
plt.scatter(usia, tinggi)
plt.show()

"""selain itu ada library lain selain maptplotlib yaitu, Seaborn merupakan turuna dari matplotlibyangpada umumnya diguanakn untuk membuat data grafik dan statistik atau boxplot.

Scikit - Learn
---
Keperluan Machine Learning salah satu alasan utamanya adalah karena adanya library scikit-Learn, Library ini banyak menyediakan modul dan model baik dari segi supervised dan unsupervised learning, yang mengutamakan penggunaan keguaan yang flexibelitas yang memadai tugas - tugas pembuatan model yang secara kompleks. untuk dokumentasi nya bagi pengguna atau pembaca bisa di akses melalui link berikut : https://scikit-learn.org/stable/index.html
"""

# contoh input dan output ketika menggunakan scikit - Learn dalam machine Learning
# pada study case dibawah ini mengklasifikasikan data erros dan test eror dan mengambil sampel datanya

import numpy as np

from sklearn import linear_model
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

n_samples_train, n_samples_test, n_features = 75, 150, 500
X, y, coef = make_regression(
    n_samples=n_samples_train + n_samples_test,
    n_features=n_features,
    n_informative=50,
    shuffle=False,
    noise=1.0,
    coef=True,
)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, train_size=n_samples_train, test_size=n_samples_test, shuffle=False
)

#mengitung kesalahan yang terjadi error pada data
alphas = np.logspace(-5, 1, 60)
enet = linear_model.ElasticNet(l1_ratio=0.7, max_iter=10000)
train_errors = list()
test_errors = list()
for alpha in alphas:
    enet.set_params(alpha=alpha)
    enet.fit(X_train, y_train)
    train_errors.append(enet.score(X_train, y_train))
    test_errors.append(enet.score(X_test, y_test))

i_alpha_optim = np.argmax(test_errors)
alpha_optim = alphas[i_alpha_optim]
print("Optimal regularization parameter : %s" % alpha_optim)

# Estimate the coef_ on full data with optimal regularization parameter
enet.set_params(alpha=alpha_optim)
coef_ = enet.fit(X, y).coef_

#menampilkan fungsi data grafik sebagai berikut menggunakan standart library Scikit - Learn
import matplotlib.pyplot as plt

plt.subplot(2, 1, 1)
plt.semilogx(alphas, train_errors, label="Train")
plt.semilogx(alphas, test_errors, label="Test")
plt.vlines(
    alpha_optim,
    plt.ylim()[0],
    np.max(test_errors),
    color="k",
    linewidth=3,
    label="Optimum on test",
)
plt.legend(loc="lower right")
plt.ylim([0, 1.2])
plt.xlabel("Regularization parameter")
plt.ylabel("Performance")

# Show estimated coef_ vs true coef
plt.subplot(2, 1, 2)
plt.plot(coef, label="True coef")
plt.plot(coef_, label="Estimated coef")
plt.legend()
plt.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.26)
plt.show()

"""SciPy
---
scipy adalah library yang digunakan yang dapat membantu menerapkan ilmu komputasi secara kompleks(seperti: Fisika Komputasi, Matematika Komputasi dan MIPA Komputasi). jika pengguna maupun pembaca tertarik bisa langsung untuk mengunjungi laman Dokumentasinya sebagai berikut: https://www.scipy.org.

MLExtend
---
Algoritma Machine Learning yang menggunakan contoh untuk dari Library extension dengan Library MLExtends untuk bisa menggunakan model Association Rules yang kebetulan belum ada di scikit - Learn dan MLExtends ini bisa di embeded kedalam mobile Programming link terkait bisa di akses disini: https://developers.google.com/ml-kit

Keras
---
library Packages ini menyediakan beragam Fungsi yang diantaranya sebagai Neural Network(Jaringan Saraf) berguna untuk Keperluan Deep Learning digunakan bersama dengan Tensorflow Kumpulan perangkat lunak yang dikembangkan oleh google dan pembaca dapat membuka kumpulan dari penggunaan dokumentasi keras dan tensor  flow
Keras : https://keras.io/,
Tensorflow : https://www.tensorflow.org/

Mengakses Database
---
Penggunaan Database pada sistem data atau pada Subjuk(Machine Learning) dalam suatu database yaitu seperti Oracle, Microsoft SQL Server MYSQL dan sejenis nya yang berelasional seperti SQL(Structed Query Languages)

SQLALchemy sebuah modul  pembantu yang bersedia untuk Python, tujuan untuk menyediakan kemudahan akses ke berbagai macam database SQL dengan konsep function doari Python. dapat dilakukan dengan instalasi dengan miniconda  prompt atau anaconda Prompt command sebagai berikut:


```
conda install -c anaconda sqlalchemy
```
"""

import pandas as pd
from sqlalchemy import create_engine, inspect
from sqlalchemy.engine.url import URL

# Define the database connection parameters
db_params = {
    "drivername": "mysql",  # Adjust the drivername to your specific database type
    "username": "root",
    "password": "",  # Provide the actual password
    "host": "192.168.0.1",
    "database": "mydatabase1",
}

# Create the engine without connecting
engine = create_engine(URL.create(**db_params))

# Check if the table exists before connecting
inspector = inspect(engine)
if 'table1' in inspector.get_table_names():
    # If the table exists, proceed with the connection
    conn = engine.connect()

    # Define your SQL query
    query = 'SELECT * FROM table1'

    # Use pandas to read data from the database
    df1 = pd.read_sql(sql=query, con=conn, chunksize=10000)

    # Close the database connection
    conn.close()
else:
    print("Table 'table1' does not exist.")

import pandas as pd
from sqlalchemy import create_engine

# Define the database connection parameters
db_params = {
    "drivername": "mysql",  # Adjust the drivername to your specific database type
    "username": "root",
    "password": "",  # Provide the actual password
    "host": "192.168.0.1",
    "database": "mydatabase1",
}

# Create the database URL
db_params = {
    "drivername": "mysql",
    "username": "root",
    "password": "your_password",
    "host": "192.168.0.1",
    "database": "mydatabase1",
}

db_url = URL(**db_params)

# Create the engine and connect to the database
engine = create_engine(db_url)
conn = engine.connect()

# Define your SQL query
query = 'SELECT * FROM table1'

# Use pandas to read data from the database
df1 = pd.read_sql(sql=query, con=conn, chunksize=10000)

# Close the database connection
conn.close()